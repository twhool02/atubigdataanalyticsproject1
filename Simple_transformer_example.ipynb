{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiODsF3IW8LIRm4TbtpDeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51e0c412656a4a3588989903748d45f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ab049dce427426e9266a863559265b1",
              "IPY_MODEL_ff08c9aabbbf4f6688f605eacaf864f5",
              "IPY_MODEL_890cfe3b9d164c6693430f6ffe856836"
            ],
            "layout": "IPY_MODEL_a34d11c5cac24517bba6df45544d1ebb"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twhool02/atubigdataanalyticsproject1/blob/main/Simple_transformer_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM6o89BPLt8x"
      },
      "outputs": [],
      "source": [
        "!pip -qq install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retrieve pipeline of modules and choose English to French translation\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "ZQxvEvawNrDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zs4FoCstNqtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_en_to_fr\")\n",
        "#One line of code!\n",
        "print(translator(\"It is easy to translate languages with transformers\",\n",
        "max_length=40))"
      ],
      "metadata": {
        "id": "l-2jkadsN2QN",
        "outputId": "794c1095-3e0f-463f-e5fa-dc138dc7b41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "51e0c412656a4a3588989903748d45f4",
            "7ab049dce427426e9266a863559265b1",
            "ff08c9aabbbf4f6688f605eacaf864f5",
            "890cfe3b9d164c6693430f6ffe856836",
            "a34d11c5cac24517bba6df45544d1ebb",
            "44749a4e737247ce901c35a0a55bdfdb",
            "96c1754a80fa459699773b945ec81939",
            "42a6bc380753423eb97283adc2eba599",
            "9f3a14b7052b465a919729c91fcb261e",
            "92bf68378aac40a8bdc914af448038c1",
            "98ac324d800e46648b0b0864b7e2eafa",
            "9d22e93f5aa544b7b0e2613c7470c42c",
            "1a606823913040fbac622cbb5cb6849b",
            "3464a510e6634a7f91d238c78532b2bf",
            "d0ca27f02d1945748ae846b8df6375a5",
            "ba99bc6aa0d04c0ca8cac72562736d67",
            "3f2d9a61645f451592fd23e3de00f18c",
            "93171db46976446e98ee4f70c9fc95f9",
            "f22268bc8f5e4e1e89abe4126ff47010",
            "084045d8957740759cd6da9041999730",
            "e4d5492c690943ffbb0db591ce5757f5",
            "04132dc3a9394d798ba477d974e8e984",
            "5d45343d39ca455d8400b9fade01de57",
            "49803c440a6949609a5e2e6a1cfdd907",
            "ef87c5eea3ac4fb28fdeaaa854cc1e92",
            "f90e51a072e34d78b82f78a9c01d92f6",
            "a78a4e0a9d724b4ca10b5c70071f19b9",
            "ad587c8080304de8919307de30538b0f",
            "dbbee849f7e04a4f96d3ee74050d1c6a",
            "23121aa079524994a09608d1a12f9476",
            "98765ae2a3b24a929f3797b095280ceb",
            "b548c6e29e4248f4bf07f66febc819f3",
            "390737a9b16d4c4991840be71fd52407",
            "9b1c457a9c8e42129b357bdb5b6fb66b",
            "e2a4b7975c294589a396f7949959c7ad",
            "c96aed3b55874ffca9301dcf9189dd2d",
            "4a5ef0863ae34aeca38b375b5756dd07",
            "93d914ea965d4e96ac443d725fadab98",
            "388b40852b98432eadd4dd8f916cc455",
            "15fd83c9df594c09b47e31f4f27ae22c",
            "e08ed26d5a334861a31b1d23f3839763",
            "e5df1fbe02804ae7a1f510f39da93012",
            "b931658772154945a1bd28b31b619583",
            "4c03634c8e4c413cb1546902e7c827f3",
            "53560f7d3fae4975b78188f7247199df",
            "cf91a2d8f9d44b8a9f45e7cbb9de0f1a",
            "faf67778d4bd4c16a05e9ccaacb1ee6e",
            "360907e3a3674952b1bedd1abe700dc6",
            "f9f9c09ebd8f4f93a59393973ba034c4",
            "875eb923b7704d729421900eb51bec9d",
            "f3a5033e66b34cd8ba63b53cf2e2f60d",
            "8f83758313fd4dbe92b200b9bcee2a18",
            "67b265228b7a484395aee7fa53ad7e70",
            "a0e303776b1e4adcb267dbb9be124477",
            "2c1b4fefb32b4c159d388e6a7c30d76b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e0c412656a4a3588989903748d45f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d22e93f5aa544b7b0e2613c7470c42c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d45343d39ca455d8400b9fade01de57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b1c457a9c8e42129b357bdb5b6fb66b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53560f7d3fae4975b78188f7247199df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': \"Il est facile de traduire des langues Ã  l'aide de transformateurs\"}]\n"
          ]
        }
      ]
    }
  ]
}